{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"audio2Spec(bo).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GiPN2ySsZ9us"},"source":["# Audio Recognition using CNN"]},{"cell_type":"markdown","metadata":{"id":"w50DvekmaJNB"},"source":["## Google Colab, Drive Configuration & Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLA2hxIefeK3","executionInfo":{"status":"ok","timestamp":1623412367078,"user_tz":-120,"elapsed":1246,"user":{"displayName":"IU FERRER","photoUrl":"","userId":"02943294489117180239"}},"outputId":"66e8df4a-1959-42e0-9384-fbde4bf61fb9"},"source":["from google.colab import drive\n","\n","import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as tf\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as img\n","\n","from PIL import Image\n","import scipy.io as sio\n","\n","import os\n","import numpy as np\n","import numpy\n","\n","#for loading and visualizing audio files\n","import librosa\n","import librosa.display\n","\n","#to play audio\n","import IPython.display as ipd\n","import skimage.io\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","data_path = '/content/drive/Shareddrives/DeepLearning/Projecte_Final/Data/'\n","spec_path = '/content/drive/Shareddrives/DeepLearning/Projecte_Final/Spectograms/'\n","results_path = '/content/drive/Shareddrives/DeepLearning/Projecte_Final/Results/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wibu53uCaRD4"},"source":["## Building the spectograms"]},{"cell_type":"code","metadata":{"id":"zT6ON-Tgppgr"},"source":["def scale_minmax(X, min=0.0, max=1.0):\n","    X_std = (X - X.min()) / (X.max() - X.min())\n","    X_scaled = X_std * (max - min) + min\n","    return X_scaled\n","    \n","def spectrogram_image(y, sr, out, hop_length, n_mels):\n","    # use log-melspectrogram\n","    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,\n","                                            n_fft=hop_length*2, hop_length=hop_length)\n","    mels = numpy.log(mels + 1e-9) # add small number to avoid log(0)\n","\n","    # min-max scale to fit inside 8-bit range\n","    img = scale_minmax(mels, 0, 255).astype(numpy.uint8)\n","    img = numpy.flip(img, axis=0) # put low frequencies at the bottom in image\n","    img = 255-img # invert. make black==more energy\n","\n","    # save as PNG\n","    skimage.io.imsave(out, img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ekBUa-qRS9D1","executionInfo":{"status":"ok","timestamp":1623318586063,"user_tz":-120,"elapsed":21608,"user":{"displayName":"VICTOR AGUADO","photoUrl":"","userId":"11637426900251361343"}},"outputId":"8d1335fd-c37d-4456-b72c-1f431ca8d028"},"source":["words = ['catapulta', 'hola', 'iu', 'mar', 'taula', 'victor']\n","audio_fpath = data_path + \"exported_audios/\"+ word +\"/\"\n","audio_clips = os.listdir(audio_fpath)\n","\n","print(\"Number of .wav files in audio folder = \",len(audio_clips))\n","\n","if len(os.listdir(spec_path + word +\"/\")) == 0:   # Last number was used in order not to convert all audios every time we got more\n","    last_number = 0\n","else:\n","    last_number = len(os.listdir(spec_path + word +\"/\"))\n","print(last_number)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of .wav files in audio folder =  1014\n","1014\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VCfSzUNAhres","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1yEtor8fDIX-t03fPTraAJbnbAqxCF7DR"},"executionInfo":{"status":"ok","timestamp":1623415132996,"user_tz":-120,"elapsed":2754660,"user":{"displayName":"IU FERRER","photoUrl":"","userId":"02943294489117180239"}},"outputId":"1d475eab-481d-466c-b024-9d8bcdcbbf8e"},"source":["# settings\n","hop_length = 512 # number of samples per time-step in spectrogram\n","n_mels = 128 # number of bins in spectrogram. Height of image\n","time_steps = 384 # number of time-steps. Width of image\n","\n","words = ['catapulta', 'hola', 'iu', 'mar', 'taula', 'victor']\n","\n","for word in words:\n","    for dt in ['Train', 'Test']:\n","\n","        audio_fpath = data_path + \"exported_audios/\"+ word + \"/\" + dt +\"/\"\n","        audio_clips = os.listdir(audio_fpath)\n","\n","        for i in range(1, len(audio_clips)+1):\n","            # load audio. Using example from librosa\n","            #path = librosa.util.example_audio_file()\n","            y, sr = librosa.load(audio_fpath + word + f'%d.mp3'%(i), sr=44100) # (path, offset=1.0, duration=10.0, sr=22050)\n","            out = spec_path + word + \"/\" + dt + f'/%d.png'%i\n","\n","            # extract a fixed length window\n","            start_sample = 0 # starting at beginning\n","            length_samples = time_steps*hop_length\n","            window = y[start_sample:start_sample+length_samples]\n","\n","            # convert to PNG\n","            spectrogram_image(window, sr=sr, out=out, hop_length=hop_length, n_mels=n_mels)\n","            print('Wrote file...', out)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"naf9b7Sk6n6a"},"source":[""],"execution_count":null,"outputs":[]}]}